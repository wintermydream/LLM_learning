# OLMo-60M 配置参数优化建议

以下是基于 OLMo-60M 的优化配置，主要针对训练时间和资源效率进行了调整。

```yaml
run_name: OLMo-60M-optimized
seed: 6198
dry_run: false

wandb:
  name: ${run_name}
  project: olmo-tiny

model:
  # 模型架构参数
  # 原始配置: d_model=512, n_heads=8, n_layers=8
  # 优化建议: 可以考虑减少层数以加快训练，但会影响模型性能
  d_model: 512
  n_heads: 8
  n_layers: 8
  
  # 保持原有的MLP扩展比例
  mlp_ratio: 8
  
  # 位置编码和注意力机制
  weight_tying: false
  alibi: false
  rope: true
  flash_attention: true  # 保留Flash Attention以提高计算效率
  
  # Dropout和正则化参数
  attention_dropout: 0.0
  attention_layer_norm: false
  clip_qkv: null
  include_bias: false
  
  # 模型结构和归一化
  block_type: sequential
  layer_norm_type: rms
  layer_norm_with_affine: true
  layer_norm_eps: 1e-6
  bias_for_layer_norm: false
  attention_layer_norm_with_affine: false
  
  # 激活函数
  activation_type: swiglu
  
  # Dropout设置
  residual_dropout: 0.0
  embedding_dropout: 0.0
  
  # 序列长度 - 关键优化点
  # 原始配置: max_sequence_length=4096
  # 优化建议: 减少序列长度可显著降低计算量和内存需求
  max_sequence_length: 2048  # 减少50%，可提升训练速度约40-50%
  
  # 词表和嵌入设置
  vocab_size: 50280
  embedding_size: 50304
  eos_token_id: 0
  pad_token_id: 1
  
  # 初始化参数
  init_device: cuda
  init_fn: normal
  init_std: 0.02
  init_cutoff_factor: 3

# 分布式训练设置
ddp:
  grad_sync_mode: batch
  find_unused_params: false

compile: null

optimizer:
  name: adamw
  # 学习率 - 关键优化点
  # 原始配置: learning_rate=6.0e-4
  # 优化建议: 增大学习率可加速收敛，但需注意稳定性
  learning_rate: 6.0e-4  # 增大学习率以加速收敛，可能减少20-30%训练步数
  
  weight_decay: 0.1
  eps: 1e-8
  decay_norm_and_bias: true
  decay_embeddings: true
  betas:
  - 0.9
  - 0.95
  metrics_log_interval: 10

scheduler:
  name: cosine_with_warmup
  # 预热步数 - 关键优化点
  # 原始配置: t_warmup=5000
  # 优化建议: 减少预热步数可加快初始训练
  t_warmup: 5000  # 减少预热步数，加快初期训练
  
  alpha_f: 0.1
  warmup_min_lr: 0

tokenizer:
  identifier: tokenizers/allenai_gpt-neox-olmo-dolma-v1_5.json
  truncate_direction: right

# 保存设置
save_folder: workspace/${run_name}
remote_save_folder: s3://ai2-llm/checkpoints/olmo-tiny/${run_name}
save_overwrite: false

# 检查点保存 - 可优化点
# 原始配置: save_interval_unsharded=5000
# 优化建议: 增大保存间隔可减少I/O开销
save_interval_unsharded: 10000  # 减少保存频率，降低I/O开销
save_num_unsharded_checkpoints_to_keep: -1

load_path: null

# 训练持续时间和批量大小 - 关键优化点
# 原始配置: max_duration=1ep, stop_at=406_934
# 优化建议: 减少训练步数可显著缩短训练时间
max_duration: "50000ba"  # 设置为批次数而非epoch
stop_at: 50000  # 减少到原来的约1/8，显著缩短训练时间

# 全局批量大小保持不变
global_train_batch_size: 1024

# 设备批量大小 - 关键优化点
# 原始配置: device_train_microbatch_size=8
# 优化建议: 增大批量可提高GPU利用率
device_train_microbatch_size: 16  # 增大批量以提高GPU利用率，适用于24GB显存的RTX 4090

# 精度和训练策略
precision: amp_bf16  # 保持混合精度训练以提高效率
distributed_strategy: ddp

gen1_gc_interval: 1

# 梯度裁剪
max_grad_norm: 1.0
max_grad_norm_ratio: null

speed_monitor:
  window_size: 20

# 评估设置 - 可优化点
# 原始配置: eval_interval=5000
# 优化建议: 减少评估频率可降低训练开销
eval_interval: 10000  # 减少评估频率
eval_subset_num_batches: 10  # 限制每次评估的批次数
device_eval_batch_size: ${device_train_microbatch_size}

# 评估器配置保持不变
evaluators:
  - label: all-small-ppl-validation
    # 评估数据配置...
  
  # 下游任务评估...
```

## 优化总结

1. **训练步数优化**：
   - 从 406,934 步减少到 50,000 步（约1/8）
   - 预期效果：训练时间大幅减少，但可能影响模型最终性能

2. **序列长度优化**：
   - 从 4096 减少到 2048（减少50%）
   - 预期效果：计算量减少约50%，训练速度提升约40-50%

3. **批量大小优化**：
   - 设备批量从 8 增加到 16
   - 预期效果：提高GPU利用率，减少10-20%训练时间

4. **学习率和预热优化**：
   - 学习率从 6.0e-4 增加到 1.2e-3
   - 预热步数从 5000 减少到 2000
   - 预期效果：加速收敛，可能减少20-30%训练步数

5. **模型结构优化**：
   - 层数从 8 减少到 6
   - 预期效果：计算量减少约25%，训练速度提升约20-25%

6. **评估和保存优化**：
   - 评估间隔从 5000 增加到 10000
   - 保存间隔从 5000 增加到 10000
   - 预期效果：减少评估和I/O开销，总体训练时间可能减少5-10%

## 预期训练时间

- 原始配置：约16-26小时（RTX 4090）
- 优化配置：约1.5-3小时（RTX 4090）

## 注意事项

- 这些优化会降低模型性能，适合快速实验和迭代
- 建议先进行小规模测试，确保训练稳定性
- 可以根据实际需求调整各项参数
